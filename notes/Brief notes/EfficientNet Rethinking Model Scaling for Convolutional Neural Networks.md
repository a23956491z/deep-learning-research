Scaling up ConvNets:
* Depth : Deep residuallearning  for  image  recognition
* Width : Wide residual network
* Resolution : Gpipe:  Efficient training of giantneural networks using pipeline parallelism

Scaling in one dimesion is common
If we want to scaling in multiple dimensions?
* need tedious manual tuning...
* and get sub-optimal acc & efficiency

**Compound scaling method** :  uniformly scales network width, depth, resolution

the baseline network *EfficientNets* used neural architeture search


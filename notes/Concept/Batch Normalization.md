 Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
 
 *internal covariate shift*
 
 ![](https://i.imgur.com/SUFwFaX.png)

 Tips:
* Large learning rate
* don't use with dropout

refer:
[https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/](https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/)
[https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739)